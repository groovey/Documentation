<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Groovey</title>




    <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>


    <link rel="stylesheet" href="css/theme.css" type="text/css" />


    <body class="wy-body-for-nav" role="document">

        <div class="wy-grid-for-nav">


            <nav data-toggle="wy-nav-shift" class="wy-nav-side">
                <div class="wy-side-nav-search">

                    <a href="../index.html" class="fa fa-home"> Mocha</a>

                </div>

                <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">


                    <ul>
                        <li class="toctree-l1"><a class="reference internal" href="../tutorial/mnist.html">Training LeNet on MNIST</a>
                            <ul>
                                <li class="toctree-l2"><a class="reference internal" href="../tutorial/mnist.html#preparing-the-data">Preparing the Data</a>
                                </li>
                                <li class="toctree-l2"><a class="reference internal" href="../tutorial/mnist.html#defining-the-network-architecture">Defining the Network Architecture</a>
                                </li>
                                <li class="toctree-l2"><a class="reference internal" href="../tutorial/mnist.html#setup-backend-and-build-network">Setup Backend and Build Network</a>
                                </li>
                                <li class="toctree-l2"><a class="reference internal" href="../tutorial/mnist.html#setup-solver">Setup Solver</a>
                                </li>
                                <li class="toctree-l2"><a class="reference internal" href="../tutorial/mnist.html#coffee-breaks-for-the-solver">Coffee Breaks for the Solver</a>
                                </li>
                                <li class="toctree-l2"><a class="reference internal" href="../tutorial/mnist.html#training">Training</a>
                                </li>
                            </ul>
                        </li>
                    </ul>
                    <ul class="current">
                        <li class="toctree-l1"><a class="reference internal" href="network.html">Networks</a>
                        </li>
                        <li class="toctree-l1"><a class="reference internal" href="blob.html">Blob</a>
                        </li>
                        <li class="toctree-l1"><a class="reference internal" href="layers/index.html">Layers</a>
                            <ul>
                                <li class="toctree-l2"><a class="reference internal" href="layers/overview.html">Overview</a>
                                </li>
                            </ul>
                        </li>
                        <li class="toctree-l1 current"><a class="current reference internal" href="">Mocha Backends</a>
                            <ul>
                                <li class="toctree-l2"><a class="reference internal" href="#pure-julia-cpu-backend">Pure Julia CPU Backend</a>
                                </li>
                                <li class="toctree-l2"><a class="reference internal" href="#cpu-backend-with-native-extension">CPU Backend with Native Extension</a>
                                </li>
                                <li class="toctree-l2"><a class="reference internal" href="#cuda-backend">CUDA Backend</a>
                                </li>
                            </ul>
                        </li>
                    </ul>


                </div>
                &nbsp;
            </nav>

            <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">


                <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
                    <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
                    <a href="../index.html">Mocha</a>
                </nav>



                <div class="wy-nav-content">
                    <div class="rst-content">
                        <div role="navigation" aria-label="breadcrumbs navigation">
                            <ul class="wy-breadcrumbs">
                                <li><a href="../index.html">Docs</a> &raquo;</li>

                                <li>Mocha Backends</li>
                                <li class="wy-breadcrumbs-aside">

                                    <a href="https://github.com/pluskid/Mocha.jl/blob/master/docs/manual/backend.rst" class="fa fa-github"> Edit on GitHub</a>

                                </li>
                            </ul>
                            <hr/>
                        </div>
                        <div role="main" class="document">

                            <div class="section" id="mocha-backends">
                                <h1>Mocha Backends<a class="headerlink" href="#mocha-backends" title="Permalink to this headline">¶</a>
                                </h1>
                                <p>A backend in Mocha is a component that carries out actual numerical computation. Mocha is designed to support multiple backends, and switching between different backends should be almost transparent to the rest of the world.</p>
                                <div class="section" id="pure-julia-cpu-backend">
                                    <h2>Pure Julia CPU Backend<a class="headerlink" href="#pure-julia-cpu-backend" title="Permalink to this headline">¶</a>
                                    </h2>
                                    <p>A pure Julia CPU backend is implemented in Julia. This backend is reasonably fast by making heavy use of the Julia&#8217;s built-in BLAS matrix computation library and <a class="reference external" href="http://julia.readthedocs.org/en/latest/manual/performance-tips/#performance-annotations">performance annotations</a>
                                        to help the LLVM-based JIT compiler producing high performance instructions.</p>
                                    <p>A pure Julia CPU backend could be instantiated by calling the constructor
                                        <tt class="docutils literal">
                                            <span class="pre">CPUBackend()</span>
                                        </tt>. Because there is no external dependency, it should runs on any platform that runs Julia.</p>
                                    <p>If you have many cores in your computer, you can play with the number of threads used by the Julia&#8217;s BLAS matrix computation library by:</p>
                                    <div class="highlight-julia">
                                        <div class="highlight"><pre><span class="n">blas_set_num_threads</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
</pre>
                                        </div>
                                    </div>
                                    <p>Depending on the problem size and a lot of other factors, using larger N is not necessarily faster.</p>
                                </div>
                                <div class="section" id="cpu-backend-with-native-extension">
                                    <h2>CPU Backend with Native Extension<a class="headerlink" href="#cpu-backend-with-native-extension" title="Permalink to this headline">¶</a>
                                    </h2>
                                    <p>Mocha comes with C++ implementations of some bottleneck computations for the CPU backend. In order to use the native extension, you need to build the native code first (if it is not built automatically when installing the package).</p>
                                    <div class="highlight-julia">
                                        <div class="highlight"><pre><span class="n">Pkg</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="s">&quot;Mocha&quot;</span><span class="p">)</span>
</pre>
                                        </div>
                                    </div>
                                    <p>After successfully building the native extension, it could be enabled by setting the environment variable. On bash or zsh, execute</p>
                                    <div class="highlight-bash">
                                        <div class="highlight"><pre><span class="nb">export </span><span class="nv">MOCHA_USE_NATIVE_EXT</span><span class="o">=</span><span class="nb">true</span>
</pre>
                                        </div>
                                    </div>
                                    <p>before running Mocha. You can also set the environment variable inside the Julia code:
                                    </p>
                                    <div class="highlight-julia">
                                        <div class="highlight"><pre><span class="n">ENV</span><span class="p">[</span><span class="s">&quot;MOCHA_USE_NATIVE_EXT&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s">&quot;true&quot;</span>

<span class="k">using</span> <span class="n">Mocha</span>
</pre>
                                        </div>
                                    </div>
                                    <p>Note you should set the environment variable
                                        <strong>before</strong>loading the Mocha module. Otherwise Mocha will not load the native extension sub-module at all.</p>
                                    <p>The native extension uses <a class="reference external" href="http://openmp.org/wp/">OpenMP</a> to do parallel computation on Linux. The number of OpenMP threads used could be controlled by the
                                        <tt class="docutils literal">
                                            <span class="pre">OMP_NUM_THREADS</span>
                                        </tt>environment variable. Note this variable is not specific to Mocha. If you have other programs that uses OpenMP, setting this environment variable in a shell will also affect those problems started subsequently. If you want to restrict to Mocha, simply set the variable in the Julia code:</p>
                                    <div class="highlight-julia">
                                        <div class="highlight"><pre><span class="n">ENV</span><span class="p">[</span><span class="s">&quot;OMP_NUM_THREADS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre>
                                        </div>
                                    </div>
                                    <p>Note setting to 1 disabled the OpenMP parallelization. Depending on the problem size and a lot of other factors, using multi-thread OpenMP parallelization is not necessarily faster because of the overhead of multi-threads.</p>
                                    <p>The parameter for the number of threads used by the BLAS library applies to the CPU backend with native extension, too.</p>
                                    <div class="section" id="openmp-on-mac-os-x">
                                        <h3>OpenMP on Mac OS X<a class="headerlink" href="#openmp-on-mac-os-x" title="Permalink to this headline">¶</a>
                                        </h3>
                                        <p>When compiling the native extension on Mac OS X, you will get a warning that OpenMP is disabled. This is because currently clang, the built-in compiler for OS X, does not officially support OpenMP yet. If you want to try OpenMP on OS X, please refer to <a class="reference external" href="http://clang-omp.github.io/">Clang-OMP</a> and compile manually (see below).</p>
                                    </div>
                                    <div class="section" id="native-extension-on-windows">
                                        <h3>Native Extension on Windows<a class="headerlink" href="#native-extension-on-windows" title="Permalink to this headline">¶</a>
                                        </h3>
                                        <p>The native extension does not support Windows because automatic building script does not work on Windows. However, the native codes themselves does not use any OS specific features. If you have a compiler installed on Windows, you could try to compile the native extension manually. However, I have
                                            <strong>not</strong>tested the native extension on Windows personally.</p>
                                    </div>
                                    <div class="section" id="compile-native-extension-manually">
                                        <h3>Compile Native Extension Manually<a class="headerlink" href="#compile-native-extension-manually" title="Permalink to this headline">¶</a>
                                        </h3>
                                        <p>The native codes are located in the
                                            <tt class="docutils literal">
                                                <span class="pre">deps</span>
                                            </tt>directory of Mocha. Use</p>
                                        <div class="highlight-julia">
                                            <div class="highlight"><pre><span class="n">Pkg</span><span class="o">.</span><span class="n">dir</span><span class="p">(</span><span class="s">&quot;Mocha&quot;</span><span class="p">)</span>
</pre>
                                            </div>
                                        </div>
                                        <p>to find out where Mocha is installed. You should compile it as a shared library (DLL on Windows). However, currently the filename for the library is hard-coded to be
                                            <tt class="docutils literal">
                                                <span class="pre">libmochaext.so</span>
                                            </tt>, with a
                                            <tt class="docutils literal">
                                                <span class="pre">.so</span>
                                            </tt>extension, regardless of the underlying OS.
                                        </p>
                                    </div>
                                </div>
                                <div class="section" id="cuda-backend">
                                    <h2>CUDA Backend<a class="headerlink" href="#cuda-backend" title="Permalink to this headline">¶</a>
                                    </h2>
                                    <p>GPU has been shown to be very effective at training large scale deep neural networks. NVidia® recently released a GPU accelerated library of primitives for deep neural networks called <a class="reference external" href="https://developer.nvidia.com/cuDNN">cuDNN</a>. Mocha implemented a CUDA backend by combining cuDNN, <a class="reference external" href="https://developer.nvidia.com/cublas">cuBLAS</a> and plain CUDA kernels.</p>
                                    <p>In order to use the CUDA backend, you need to have CUDA-compatible GPU devices. The CUDA toolkit should be installed in order to compile the Mocha CUDA kernels. cuBLAS is included in CUDA distribution. But cuDNN needs to be installed separately. You could obtain cuDNN from <a class="reference external" href="https://developer.nvidia.com/cuDNN">Nvidia&#8217;s website</a> by registering as a CUDA developer for free <a class="footnote-reference" href="#id2" id="id1">[1]</a>.</p>
                                    <p>Before using the CUDA backend, Mocha kernels needs to be compiled. The kernels are located in
                                        <tt class="docutils literal">
                                            <span class="pre">src/cuda/kernels</span>
                                        </tt>. Please use
                                        <tt class="docutils literal">
                                            <span class="pre">Pkg.dir(&quot;Mocha&quot;)</span>
                                        </tt>to find out where Mocha is installed on your system. We have included a Makefile for convenience, but if you don&#8217;t have
                                        <tt class="docutils literal">
                                            <span class="pre">make</span>
                                        </tt>installed, the compiling command is as simple as</p>
                                    <div class="highlight-bash">
                                        <div class="highlight"><pre>nvcc -ptx kernels.cu
</pre>
                                        </div>
                                    </div>
                                    <p>After compiling the kernels, you can now start to use the CUDA backend by setting the environment variable
                                        <tt class="docutils literal">
                                            <span class="pre">MOCHA_USE_CUDA</span>
                                        </tt>. For example:</p>
                                    <div class="highlight-julia">
                                        <div class="highlight"><pre><span class="n">ENV</span><span class="p">[</span><span class="s">&quot;MOCHA_USE_CUDA&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s">&quot;true&quot;</span>

<span class="k">using</span> <span class="n">Mocha</span>

<span class="n">sys</span> <span class="o">=</span> <span class="n">System</span><span class="p">(</span><span class="n">CuDNNBackend</span><span class="p">())</span>
<span class="n">init</span><span class="p">(</span><span class="n">sys</span><span class="p">)</span>

<span class="c"># ...</span>

<span class="n">shutdown</span><span class="p">(</span><span class="n">sys</span><span class="p">)</span>
</pre>
                                        </div>
                                    </div>
                                    <p>Note instead of instantiate a
                                        <tt class="docutils literal">
                                            <span class="pre">CPUBackend</span>
                                        </tt>, you now construct a
                                        <tt class="docutils literal">
                                            <span class="pre">CuDNNBackend</span>
                                        </tt>. The environment variable should be set
                                        <strong>before</strong>loading Mocha. It is designed to use conditional loading so that the pure CPU backend could still run on machines without any GPU device or CUDA library installed.</p>
                                    <table class="docutils footnote" frame="void" id="id2" rules="none">
                                        <colgroup>
                                            <col class="label" />
                                            <col />
                                        </colgroup>
                                        <tbody valign="top">
                                            <tr>
                                                <td class="label"><a class="fn-backref" href="#id1">[1]</a>
                                                </td>
                                                <td>cuDNN requires CUDA 6.5 to run, and currently cuDNN is available to Linux and Windows only.</td>
                                            </tr>
                                        </tbody>
                                    </table>
                                </div>
                            </div>


                        </div>


                        <footer>
                            <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
                                <a href="layers/overview.html" class="btn btn-neutral" title="Overview">
                                    <span class="fa fa-arrow-circle-left"></span>Previous
                                </a>
                            </div>
                            <hr/>
                            <div role="contentinfo">
                                <p>
                                    &copy; Copyright 2014, pluskid.
                                </p>
                            </div>
                            Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
                        </footer>
                    </div>
                </div>

            </section>

        </div>




    </body>

</html>
